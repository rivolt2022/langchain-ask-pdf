from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.chat_models import ChatOpenAI  # ëŒ€í™” ê¸°ë°˜ ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•œ ì—…ë°ì´íŠ¸
from langchain.callbacks import get_openai_callback

def main():
    # í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ (ì˜ˆ: OpenAI API í‚¤)
    load_dotenv()

    # Streamlit í˜ì´ì§€ ì„¤ì • (í˜ì´ì§€ ì œëª© ì„¤ì •)
    st.set_page_config(page_title="ì—°ì„¸ëŒ€í•™êµ í–‰ì • í˜ì‹ ")
    st.header("ì—°ì„¸ëŒ€í•™êµ í–‰ì • í˜ì‹  ì˜ˆì œ ì±—ë´‡ğŸ’¬")  # í˜ì´ì§€ í—¤ë” ì„¤ì •

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì²˜ë¦¬ ì¤‘ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ í”Œë˜ê·¸)
    if 'processing' not in st.session_state:
        st.session_state['processing'] = False

    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ (PDF íŒŒì¼ ì—…ë¡œë“œ)
    pdf = st.file_uploader("í–‰ì • ë§¤ë‰´ì–¼ì„ PDFë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", type="pdf")
    
    # PDF íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°
    if pdf is not None:
        pdf_reader = PdfReader(pdf)  # PDF ë¦¬ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ ì½ê¸°
        text = ""
        # ê° í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ
        for page in pdf_reader.pages:
            text += page.extract_text()
        
        # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• 
        text_splitter = CharacterTextSplitter(
            separator="\n",  # ì¤„ë°”ê¿ˆì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
            chunk_size=1000,  # ê° ì²­í¬ì˜ ìµœëŒ€ í¬ê¸° ì„¤ì •
            chunk_overlap=200,  # ì²­í¬ ê°„ ì¤‘ì²© ì„¤ì •
            length_function=len  # í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚° í•¨ìˆ˜
        )
        chunks = text_splitter.split_text(text)  # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        
        # ì„ë² ë”© ìƒì„± (OpenAI ì„ë² ë”© ì‚¬ìš©)
        embeddings = OpenAIEmbeddings()
        # FAISSë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­í¬ë¡œë¶€í„° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤(knowledge base) ìƒì„±
        knowledge_base = FAISS.from_texts(chunks, embeddings)

        # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì…ë ¥ë°›ëŠ” í¼ ìƒì„±
        with st.form(key="user_question_form", clear_on_submit=True):
            user_question = st.text_input(
                "PDFì— ëŒ€í•´ì„œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”:",  # ì§ˆë¬¸ ì…ë ¥ì°½ ë ˆì´ë¸”
                disabled=st.session_state['processing']  # ì²˜ë¦¬ ì¤‘ì¼ ë•Œ ì…ë ¥ ë¹„í™œì„±í™”
            )
            # í¼ ì œì¶œ ë²„íŠ¼
            submit_button = st.form_submit_button(label="ì§ˆë¬¸ ì œì¶œ")

        # í¼ì´ ì œì¶œë˜ì—ˆê³ , ì§ˆë¬¸ì´ ì…ë ¥ë˜ì—ˆìœ¼ë©° í˜„ì¬ ì²˜ë¦¬ê°€ ì§„í–‰ ì¤‘ì´ ì•„ë‹Œ ê²½ìš°
        if submit_button and user_question and not st.session_state['processing']:
            # ì²˜ë¦¬ ì¤‘ í”Œë˜ê·¸ë¥¼ Trueë¡œ ì„¤ì •í•˜ì—¬ ì…ë ¥ ë¹„í™œì„±í™”
            st.session_state['processing'] = True

            # ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ìŠ¤í”¼ë„ˆ í‘œì‹œ
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ë‹µë³€ ìƒì„±ì¤‘ 'ì§ˆë¬¸ ì œì¶œ' í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”."):
                # ì§ˆë¬¸ì— ëŒ€í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
                docs = knowledge_base.similarity_search(user_question)
                
                # ëŒ€í™” ê¸°ë°˜ LLM ëª¨ë¸ ì‚¬ìš© (ì˜ˆ: GPT-4-turbo)
                llm = ChatOpenAI(model="gpt-4-turbo")  # GPT-4-turbo ëª¨ë¸ ì‚¬ìš©
                chain = load_qa_chain(llm, chain_type="stuff")  # ì§ˆë¬¸-ì‘ë‹µ ì²´ì¸ ìƒì„±
                
                # OpenAI API í˜¸ì¶œì— ëŒ€í•œ ì‚¬ìš©ëŸ‰ ì½œë°± ì²˜ë¦¬
                with get_openai_callback() as cb:
                    # ìœ ì‚¬í•œ ë¬¸ì„œì— ê¸°ë°˜í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€ ìƒì„±
                    response = chain.run(input_documents=docs, question=user_question)
                    print(cb)  # API í˜¸ì¶œ ë¡œê·¸ ì¶œë ¥
                
                # ìƒì„±ëœ ë‹µë³€ì„ í™”ë©´ì— ì¶œë ¥
                st.write(response)
            
            # ì²˜ë¦¬ ì™„ë£Œ í›„ í”Œë˜ê·¸ë¥¼ Falseë¡œ ë‹¤ì‹œ ì„¤ì •í•˜ì—¬ ì…ë ¥ í™œì„±í™”
            st.session_state['processing'] = False

# ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
if __name__ == '__main__':
    main()
